{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Date & Time Operations - Python Exercises\n",
    "**Business Scenario**: NaijaCommerce Seasonal Analysis & Operations Optimization\n",
    "**Instructions**: Complete each exercise to help NaijaCommerce understand their temporal business patterns using Python\n",
    "\n",
    "## üéØ Exercise Overview\n",
    "These exercises mirror the SQL exercises from Thursday's class, allowing you to compare approaches and validate that both tools can achieve the same business insights.\n",
    "\n",
    "## üìö Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üì¶ Libraries imported successfully!\")\n",
    "print(\"üöÄ Ready to start temporal analysis exercises!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset (equivalent to our SQL dataset)\n",
    "np.random.seed(42)\n",
    "n_orders = 12000\n",
    "start_date = datetime(2017, 1, 1)\n",
    "end_date = datetime(2018, 12, 31)\n",
    "\n",
    "# Generate orders dataset\n",
    "orders_df = pd.DataFrame({\n",
    "    'order_id': [f'order_{i:06d}' for i in range(n_orders)],\n",
    "    'customer_id': [f'customer_{np.random.randint(1, 6000):06d}' for _ in range(n_orders)],\n",
    "    'order_purchase_timestamp': pd.date_range(start=start_date, end=end_date, periods=n_orders),\n",
    "    'order_status': np.random.choice(['delivered', 'shipped', 'cancelled', 'unavailable'], \n",
    "                                   n_orders, p=[0.80, 0.12, 0.06, 0.02])\n",
    "})\n",
    "\n",
    "# Add delivery and approval timestamps\n",
    "approval_delays = np.random.exponential(scale=1.5, size=n_orders)\n",
    "delivery_delays = np.random.exponential(scale=9, size=n_orders) + approval_delays\n",
    "\n",
    "orders_df['order_approved_at'] = orders_df['order_purchase_timestamp'] + pd.to_timedelta(approval_delays, unit='D')\n",
    "orders_df['order_delivered_customer_date'] = orders_df['order_purchase_timestamp'] + pd.to_timedelta(delivery_delays, unit='D')\n",
    "orders_df['order_estimated_delivery_date'] = orders_df['order_purchase_timestamp'] + pd.to_timedelta(10, unit='D')\n",
    "\n",
    "# Set delivery dates to None for non-delivered orders\n",
    "mask = orders_df['order_status'] != 'delivered'\n",
    "orders_df.loc[mask, 'order_delivered_customer_date'] = pd.NaT\n",
    "\n",
    "# Create order items with pricing (for revenue analysis)\n",
    "delivered_orders = orders_df[orders_df['order_status'] == 'delivered'].copy()\n",
    "order_items = []\n",
    "for _, order in delivered_orders.iterrows():\n",
    "    n_items = np.random.choice([1, 2, 3], p=[0.75, 0.20, 0.05])\n",
    "    for item_id in range(n_items):\n",
    "        order_items.append({\n",
    "            'order_id': order['order_id'],\n",
    "            'order_item_id': item_id + 1,\n",
    "            'price': np.random.exponential(scale=45) + 15,  # Price distribution\n",
    "            'product_id': f'product_{np.random.randint(1, 800):04d}'\n",
    "        })\n",
    "\n",
    "order_items_df = pd.DataFrame(order_items)\n",
    "\n",
    "print(f\"üìä Dataset created: {len(orders_df):,} orders, {len(order_items_df):,} items\")\n",
    "print(f\"üìÖ Date range: {orders_df['order_purchase_timestamp'].min().date()} to {orders_df['order_purchase_timestamp'].max().date()}\")\n",
    "print(f\"üéØ Delivered orders: {(orders_df['order_status'] == 'delivered').sum():,}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nüìã Sample Orders Data:\")\n",
    "orders_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Exercise Set 1: Basic Date Extraction and Formatting\n",
    "**Business Context**: The marketing team needs temporal insights for strategic planning.\n",
    "\n",
    "### Exercise 1.1: Monthly Sales Overview\n",
    "**Task**: Create a monthly summary showing year, month, month name, total orders, and unique customers for 2017-2018.\n",
    "\n",
    "**Expected Output**: DataFrame with columns: year, month, month_name, total_orders, unique_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.1: Monthly Sales Overview\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Use .dt accessor to extract year and month, then group by these components\n",
    "# Filter for orders in 2017-2018 and exclude cancelled/unavailable orders\n",
    "\n",
    "# Steps:\n",
    "# 1. Filter data for 2017-2018 and valid order statuses\n",
    "# 2. Extract year, month, and month_name from order_purchase_timestamp\n",
    "# 3. Group by year and month\n",
    "# 4. Count orders and unique customers\n",
    "\n",
    "monthly_sales = # Your solution here\n",
    "\n",
    "print(\"üìä Monthly Sales Overview:\")\n",
    "print(monthly_sales)\n",
    "\n",
    "# Bonus: Create a simple visualization\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# Add your visualization code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Weekend vs Weekday Shopping Patterns\n",
    "**Task**: Compare shopping patterns between weekdays and weekends.\n",
    "\n",
    "**Expected Output**: DataFrame showing day_type, total_orders, percentage_of_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.2: Weekend vs Weekday Shopping Patterns\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Use .dt.dayofweek (0=Monday, 6=Sunday) and classify days as Weekend/Weekday\n",
    "\n",
    "# Steps:\n",
    "# 1. Add day_of_week column using .dt.dayofweek\n",
    "# 2. Create day_type column (Weekend for Saturday/Sunday, Weekday otherwise)\n",
    "# 3. Group by day_type and count orders\n",
    "# 4. Calculate percentages\n",
    "\n",
    "day_type_analysis = # Your solution here\n",
    "\n",
    "print(\"üìÖ Weekend vs Weekday Shopping Patterns:\")\n",
    "print(day_type_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Peak Shopping Hours Analysis\n",
    "**Task**: Find the top 5 shopping hours by order volume.\n",
    "\n",
    "**Expected Output**: DataFrame with hour_of_day, order_count, and rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.3: Peak Shopping Hours Analysis\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Extract hour from timestamp and count orders by hour\n",
    "\n",
    "# Steps:\n",
    "# 1. Extract hour from order_purchase_timestamp\n",
    "# 2. Group by hour and count orders\n",
    "# 3. Sort by order count and get top 5\n",
    "# 4. Add rank column\n",
    "\n",
    "peak_hours = # Your solution here\n",
    "\n",
    "print(\"üïê Peak Shopping Hours:\")\n",
    "print(peak_hours)\n",
    "\n",
    "# Bonus: Create a bar chart of all 24 hours\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# Add your visualization code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí∞ Exercise Set 2: Seasonal Revenue Analysis\n",
    "**Business Context**: Executive team wants to understand revenue patterns and growth trends.\n",
    "\n",
    "### Exercise 2.1: Quarterly Performance Comparison\n",
    "**Task**: Calculate revenue and orders by quarter, including quarter-over-quarter growth rates.\n",
    "\n",
    "**Expected Output**: DataFrame with year, quarter, total_orders, total_revenue, qoq_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.1: Quarterly Performance Comparison\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Merge orders with order_items, extract quarters, use shift() for growth calculation\n",
    "\n",
    "# Steps:\n",
    "# 1. Merge orders_df with order_items_df\n",
    "# 2. Extract year and quarter from order_purchase_timestamp\n",
    "# 3. Group by year and quarter, calculate totals\n",
    "# 4. Use shift() to get previous quarter values\n",
    "# 5. Calculate quarter-over-quarter growth\n",
    "\n",
    "quarterly_performance = # Your solution here\n",
    "\n",
    "print(\"üìä Quarterly Performance with Growth:\")\n",
    "print(quarterly_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Holiday Season Impact Analysis\n",
    "**Task**: Find months with above-average sales and classify them as peak/regular periods.\n",
    "\n",
    "**Expected Output**: DataFrame with month, month_name, total_revenue, avg_revenue_all_months, classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.2: Holiday Season Impact Analysis\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Calculate monthly revenue, then compare each month to overall average\n",
    "\n",
    "# Steps:\n",
    "# 1. Merge orders with items and group by month\n",
    "# 2. Calculate total revenue per month\n",
    "# 3. Calculate overall average revenue\n",
    "# 4. Classify months as Peak/Regular/Low based on performance vs average\n",
    "\n",
    "holiday_impact = # Your solution here\n",
    "\n",
    "print(\"üéÑ Holiday Season Impact Analysis:\")\n",
    "print(holiday_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3: Year-over-Year Growth Analysis\n",
    "**Task**: Calculate month-over-month growth comparing 2017 vs 2018.\n",
    "\n",
    "**Expected Output**: DataFrame with year, month, total_orders, prev_year_orders, yoy_growth_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.3: Year-over-Year Growth Analysis\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Create monthly summary, then use shift(12) to get same month previous year\n",
    "\n",
    "# Steps:\n",
    "# 1. Group by year and month to get monthly order counts\n",
    "# 2. Use shift(12) to get same month previous year\n",
    "# 3. Calculate year-over-year growth percentage\n",
    "# 4. Filter for months where comparison is possible\n",
    "\n",
    "yoy_growth = # Your solution here\n",
    "\n",
    "print(\"üìà Year-over-Year Growth Analysis:\")\n",
    "print(yoy_growth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöö Exercise Set 3: Delivery Performance Metrics\n",
    "**Business Context**: Logistics team needs to understand seasonal delivery performance.\n",
    "\n",
    "### Exercise 3.1: Average Delivery Time by Month\n",
    "**Task**: Calculate average delivery time and identify months with poor performance.\n",
    "\n",
    "**Expected Output**: DataFrame with month_year, total_deliveries, avg_delivery_days, performance_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.1: Average Delivery Time by Month\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Filter delivered orders, calculate delivery time using date arithmetic\n",
    "\n",
    "# Steps:\n",
    "# 1. Filter for delivered orders only\n",
    "# 2. Calculate delivery_days = (delivered_date - purchase_date).dt.days\n",
    "# 3. Group by month-year and calculate average delivery days\n",
    "# 4. Add performance rating based on delivery time thresholds\n",
    "\n",
    "delivery_performance = # Your solution here\n",
    "\n",
    "print(\"üì¶ Monthly Delivery Performance:\")\n",
    "print(delivery_performance)\n",
    "\n",
    "# Bonus: Create a line chart showing delivery time trends\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# Add your visualization code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Delivery Performance Benchmarking\n",
    "**Task**: Calculate delivery time percentiles for setting performance targets.\n",
    "\n",
    "**Expected Output**: DataFrame with year, p50_delivery_days, p75_delivery_days, p95_delivery_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.2: Delivery Performance Benchmarking\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Use .quantile() method for percentile calculations\n",
    "\n",
    "# Steps:\n",
    "# 1. Filter delivered orders and calculate delivery days\n",
    "# 2. Group by year\n",
    "# 3. Calculate 50th, 75th, and 95th percentiles using .quantile()\n",
    "\n",
    "delivery_benchmarks = # Your solution here\n",
    "\n",
    "print(\"üìä Delivery Performance Benchmarks:\")\n",
    "print(delivery_benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Late Delivery Analysis\n",
    "**Task**: Find orders delivered later than estimated and analyze patterns.\n",
    "\n",
    "**Expected Output**: DataFrame with month, total_orders, late_deliveries, late_delivery_rate, avg_delay_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.3: Late Delivery Analysis\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Compare delivered_date with estimated_delivery_date\n",
    "\n",
    "# Steps:\n",
    "# 1. Filter delivered orders with both delivery and estimated dates\n",
    "# 2. Create is_late column: delivered_date > estimated_date\n",
    "# 3. Calculate delay_days for late orders\n",
    "# 4. Group by month and calculate late delivery statistics\n",
    "\n",
    "late_delivery_analysis = # Your solution here\n",
    "\n",
    "print(\"‚ö†Ô∏è Late Delivery Analysis:\")\n",
    "print(late_delivery_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë• Exercise Set 4: Customer Behavior Temporal Analysis\n",
    "**Business Context**: Marketing wants to understand customer engagement patterns.\n",
    "\n",
    "### Exercise 4.1: Customer Purchase Frequency by Season\n",
    "**Task**: Analyze how often customers make repeat purchases by quarter.\n",
    "\n",
    "**Expected Output**: DataFrame with quarter, total_customers, repeat_customers, repeat_purchase_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.1: Customer Purchase Frequency by Season\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Group by customer and quarter, count orders per customer per quarter\n",
    "\n",
    "# Steps:\n",
    "# 1. Extract quarter from order_purchase_timestamp\n",
    "# 2. Group by customer_id and quarter, count orders per customer per quarter\n",
    "# 3. Identify customers with multiple orders in the same quarter\n",
    "# 4. Calculate repeat purchase rates by quarter\n",
    "\n",
    "customer_frequency = # Your solution here\n",
    "\n",
    "print(\"üë• Customer Purchase Frequency by Quarter:\")\n",
    "print(customer_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: New vs Returning Customer Trends\n",
    "**Task**: Identify customer acquisition patterns by month.\n",
    "\n",
    "**Expected Output**: DataFrame with month_year, new_customers, returning_customers, customer_mix_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.2: New vs Returning Customer Trends\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Find each customer's first order date, then classify subsequent orders\n",
    "\n",
    "# Steps:\n",
    "# 1. Find first order date for each customer\n",
    "# 2. For each order, determine if it's the customer's first order (new) or not (returning)\n",
    "# 3. Group by month and count new vs returning customers\n",
    "# 4. Calculate customer mix ratio\n",
    "\n",
    "new_vs_returning = # Your solution here\n",
    "\n",
    "print(\"üÜï New vs Returning Customer Trends:\")\n",
    "print(new_vs_returning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3: Customer Lifetime Analysis\n",
    "**Task**: Analyze customer purchase spans and frequency.\n",
    "\n",
    "**Expected Output**: DataFrame with customer_lifetime_category, customer_count, avg_orders_per_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.3: Customer Lifetime Analysis\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Calculate time between first and last order for each customer\n",
    "\n",
    "# Steps:\n",
    "# 1. For each customer, find first and last order dates\n",
    "# 2. Calculate customer lifetime in months\n",
    "# 3. Group customers into lifetime categories (0, 1-3, 4-6, 7-12, 12+ months)\n",
    "# 4. Calculate average orders per customer in each category\n",
    "\n",
    "customer_lifetime = # Your solution here\n",
    "\n",
    "print(\"‚è≥ Customer Lifetime Analysis:\")\n",
    "print(customer_lifetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Exercise Set 5: Advanced Temporal Business Intelligence\n",
    "**Business Context**: Advanced analytics for trend identification and forecasting.\n",
    "\n",
    "### Exercise 5.1: Rolling Averages for Trend Analysis\n",
    "**Task**: Calculate 7-day and 30-day moving averages for daily orders.\n",
    "\n",
    "**Expected Output**: DataFrame with date, daily_orders, rolling_7d_avg, rolling_30d_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.1: Rolling Averages for Trend Analysis\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Group by date, then use .rolling() method for moving averages\n",
    "\n",
    "# Steps:\n",
    "# 1. Group orders by date (order_purchase_timestamp.dt.date)\n",
    "# 2. Count daily orders\n",
    "# 3. Sort by date\n",
    "# 4. Calculate 7-day and 30-day rolling averages using .rolling()\n",
    "\n",
    "rolling_analysis = # Your solution here\n",
    "\n",
    "print(\"üìä Rolling Averages Analysis (first 20 days):\")\n",
    "print(rolling_analysis.head(20))\n",
    "\n",
    "# Bonus: Create a line chart showing daily orders with moving averages\n",
    "# plt.figure(figsize=(15, 6))\n",
    "# Add your visualization code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2: Cohort Analysis by Registration Month\n",
    "**Task**: Create a cohort analysis showing customer retention rates.\n",
    "\n",
    "**Expected Output**: DataFrame with cohort_month, months_since_first_order, active_customers, retention_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.2: Cohort Analysis by Registration Month\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Group customers by first purchase month, track subsequent activity\n",
    "\n",
    "# Steps:\n",
    "# 1. Find first purchase month for each customer (cohort_month)\n",
    "# 2. For each order, calculate months since first purchase\n",
    "# 3. Group by cohort_month and months_since_first_purchase\n",
    "# 4. Count active customers and calculate retention rates\n",
    "# 5. Focus on first 12 months and recent cohorts\n",
    "\n",
    "cohort_analysis = # Your solution here\n",
    "\n",
    "print(\"üë• Cohort Analysis (sample):\")\n",
    "print(cohort_analysis.head(15))\n",
    "\n",
    "# Bonus: Create a cohort heatmap\n",
    "# cohort_matrix = cohort_analysis.pivot(index='cohort_month', \n",
    "#                                      columns='months_since_first_order', \n",
    "#                                      values='retention_rate')\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(cohort_matrix, annot=True, fmt='.1f', cmap='Blues')\n",
    "# plt.title('Customer Cohort Retention Heatmap')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.3: Seasonal Inventory Planning Analysis\n",
    "**Task**: Calculate seasonal demand patterns with predictive insights.\n",
    "\n",
    "**Expected Output**: DataFrame with month, avg_orders, seasonal_index, recommended_stock_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.3: Seasonal Inventory Planning Analysis\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Calculate seasonal indices by comparing monthly averages to yearly average\n",
    "\n",
    "# Steps:\n",
    "# 1. Group orders by month (across all years)\n",
    "# 2. Calculate average monthly orders\n",
    "# 3. Calculate seasonal index: (monthly_avg / yearly_avg) * 100\n",
    "# 4. Create stock level recommendations based on seasonal index\n",
    "\n",
    "seasonal_planning = # Your solution here\n",
    "\n",
    "print(\"üì¶ Seasonal Inventory Planning:\")\n",
    "print(seasonal_planning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåç Exercise Set 6: Nigerian Business Context\n",
    "**Business Context**: Adapt analysis for Nigerian market conditions and cultural patterns.\n",
    "\n",
    "### Exercise 6.1: Rainy Season Impact Analysis\n",
    "**Task**: Compare delivery performance between rainy and dry seasons.\n",
    "\n",
    "**Expected Output**: DataFrame with season_type, avg_delivery_days, order_volume, delivery_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6.1: Rainy Season Impact Analysis\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Classify months into Rainy (May-Oct) and Dry (Nov-Apr) seasons\n",
    "\n",
    "# Steps:\n",
    "# 1. Create function to classify months into Nigerian seasons\n",
    "# 2. Apply to delivery data\n",
    "# 3. Group by season and calculate delivery metrics\n",
    "# 4. Add performance classification\n",
    "\n",
    "def get_nigerian_season(month):\n",
    "    # Define the function here\n",
    "    pass\n",
    "\n",
    "rainy_season_impact = # Your solution here\n",
    "\n",
    "print(\"üåßÔ∏è Rainy Season Impact Analysis:\")\n",
    "print(rainy_season_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2: Nigerian Holiday Impact Analysis\n",
    "**Task**: Identify sales spikes around major Nigerian holidays.\n",
    "\n",
    "**Expected Output**: DataFrame with month, holiday_type, avg_monthly_orders, sales_spike_factor, recommended_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6.2: Nigerian Holiday Impact Analysis\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Classify months by Nigerian holidays and business periods\n",
    "\n",
    "# Steps:\n",
    "# 1. Create function to classify Nigerian business periods\n",
    "# 2. Calculate average monthly orders by business period\n",
    "# 3. Calculate sales spike factor compared to normal periods\n",
    "# 4. Add business recommendations\n",
    "\n",
    "def get_nigerian_business_period(month):\n",
    "    # Define the function here\n",
    "    # December: Christmas Season\n",
    "    # October: Independence Month\n",
    "    # September: Back-to-School\n",
    "    # Other months: Regular Period\n",
    "    pass\n",
    "\n",
    "holiday_impact = # Your solution here\n",
    "\n",
    "print(\"üéÑ Nigerian Holiday Impact Analysis:\")\n",
    "print(holiday_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3: Business Day vs Holiday Analysis\n",
    "**Task**: Compare business metrics between regular business days and holidays.\n",
    "\n",
    "**Expected Output**: DataFrame with day_type, avg_daily_orders, customer_behavior_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6.3: Business Day vs Holiday Analysis\n",
    "# YOUR CODE HERE:\n",
    "# Hint: Classify days into Business Day, Weekend, and specific holidays\n",
    "\n",
    "# Steps:\n",
    "# 1. Extract day of week and specific dates (Christmas, Independence Day)\n",
    "# 2. Classify each order date as Business Day, Weekend, or Holiday\n",
    "# 3. Calculate average daily orders by day type\n",
    "# 4. Add customer behavior pattern insights\n",
    "\n",
    "def classify_day_type(row):\n",
    "    # Define the function here\n",
    "    # Consider: weekends, Christmas (Dec 25), Independence Day (Oct 1)\n",
    "    pass\n",
    "\n",
    "business_day_analysis = # Your solution here\n",
    "\n",
    "print(\"üìÖ Business Day vs Holiday Analysis:\")\n",
    "print(business_day_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Validation and Comparison\n",
    "**Task**: Compare your Python results with Thursday's SQL findings.\n",
    "\n",
    "### Final Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive summary dashboard\n",
    "# YOUR CODE HERE: Combine insights from all exercises\n",
    "\n",
    "print(\"üìä NAIJACOMMERCE TEMPORAL ANALYSIS DASHBOARD\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Dataset overview\n",
    "print(f\"üìã DATASET OVERVIEW:\")\n",
    "print(f\"   Total Orders: {len(orders_df):,}\")\n",
    "print(f\"   Date Range: {orders_df['order_purchase_timestamp'].min().date()} to {orders_df['order_purchase_timestamp'].max().date()}\")\n",
    "print(f\"   Delivered Orders: {(orders_df['order_status'] == 'delivered').sum():,}\")\n",
    "\n",
    "# Add more summary statistics from your exercises\n",
    "# Peak shopping periods\n",
    "# Delivery performance metrics\n",
    "# Customer behavior insights\n",
    "# Seasonal patterns\n",
    "\n",
    "print(\"\\n‚úÖ Analysis Complete!\")\n",
    "print(\"üîÑ Compare these results with your Thursday SQL analysis\")\n",
    "print(\"üí° Both tools should provide identical business insights!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Reflection Questions\n",
    "\n",
    "After completing the exercises, reflect on these questions:\n",
    "\n",
    "1. **Tool Comparison**: Which operations were easier in Python vs SQL? Why?\n",
    "\n",
    "2. **Business Insights**: Did you discover the same patterns using Python as you did with SQL?\n",
    "\n",
    "3. **Visualization**: How did Python's visualization capabilities enhance your understanding?\n",
    "\n",
    "4. **Performance**: For which types of analysis would you prefer Python over SQL?\n",
    "\n",
    "5. **Integration**: How could you combine SQL and Python in a real business workflow?\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "These datetime skills will be essential for:\n",
    "- **Google Looker Studio**: Creating time-based dashboards and reports\n",
    "- **Streamlit**: Building interactive temporal analytics applications\n",
    "- **Advanced Analytics**: Time series forecasting and predictive modeling\n",
    "- **Business Intelligence**: Automated reporting and KPI tracking systems\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Submission Guidelines\n",
    "\n",
    "1. **Complete all exercises** with working code and business insights\n",
    "2. **Add visualizations** where indicated to enhance understanding\n",
    "3. **Compare results** with your Thursday SQL analysis\n",
    "4. **Include business interpretations** of your findings\n",
    "5. **Test your code** to ensure it runs without errors\n",
    "\n",
    "**Evaluation Criteria**:\n",
    "- Correct implementation of datetime operations (40%)\n",
    "- Business relevance and insight quality (30%)\n",
    "- Code quality and pandas best practices (20%)\n",
    "- Consistency with SQL analysis results (10%)\n",
    "\n",
    "Good luck with your analysis! üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}