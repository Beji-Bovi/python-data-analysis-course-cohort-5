{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Date & Time Operations - Part 2: Advanced DateTime Analysis\n",
    "**Business Scenario**: NaijaCommerce Delivery Performance & Customer Analytics\n",
    "**Focus**: Date arithmetic, time series analysis, and business intelligence\n",
    "\n",
    "## Learning Objectives\n",
    "- Perform date arithmetic using timedelta operations\n",
    "- Calculate business metrics like delivery times and customer lifetime\n",
    "- Use rolling windows and period-over-period comparisons\n",
    "- Create time-based cohort analysis for business insights"
   ]  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Setup and Data Loading\n",
    "Let's start with our imports and recreate our dataset from Part 1."
   ]  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üì¶ All libraries imported successfully!\")"
   ]  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate our sample dataset\n",
    "np.random.seed(42)\n",
    "n_orders = 15000\n",
    "start_date = datetime(2017, 1, 1)\n",
    "end_date = datetime(2018, 12, 31)\n",
    "\n",
    "# Generate realistic e-commerce data\n",
    "orders_df = pd.DataFrame({\n",
    "    'order_id': [f'order_{i:06d}' for i in range(n_orders)],\n",
    "    'customer_id': [f'customer_{np.random.randint(1, 8000):06d}' for _ in range(n_orders)],\n",
    "    'order_purchase_timestamp': pd.date_range(start=start_date, end=end_date, periods=n_orders),\n",
    "    'order_status': np.random.choice(['delivered', 'shipped', 'cancelled'], n_orders, p=[0.82, 0.13, 0.05])\n",
    "})\n",
    "\n",
    "# Add realistic delivery and approval timestamps\n",
    "approval_delays = np.random.exponential(scale=1.2, size=n_orders)\n",
    "delivery_delays = np.random.exponential(scale=8, size=n_orders) + approval_delays\n",
    "\n",
    "orders_df['order_approved_at'] = orders_df['order_purchase_timestamp'] + pd.to_timedelta(approval_delays, unit='D')\n",
    "orders_df['order_delivered_customer_date'] = orders_df['order_purchase_timestamp'] + pd.to_timedelta(delivery_delays, unit='D')\n",
    "orders_df['order_estimated_delivery_date'] = orders_df['order_purchase_timestamp'] + pd.to_timedelta(10, unit='D')  # Standard 10-day estimate\n",
    "\n",
    "# Set delivery dates to None for non-delivered orders\n",
    "mask = orders_df['order_status'] != 'delivered'\n",
    "orders_df.loc[mask, 'order_delivered_customer_date'] = pd.NaT\n",
    "\n",
    "# Create order items with pricing\n",
    "delivered_orders = orders_df[orders_df['order_status'] == 'delivered'].copy()\n",
    "order_items = []\n",
    "for _, order in delivered_orders.iterrows():\n",
    "    n_items = np.random.choice([1, 2, 3], p=[0.7, 0.25, 0.05])  # Most orders have 1 item\n",
    "    for item_id in range(n_items):\n",
    "        order_items.append({\n",
    "            'order_id': order['order_id'],\n",
    "            'order_item_id': item_id + 1,\n",
    "            'price': np.random.exponential(scale=50) + 10,  # Price between 10-200 with exponential distribution\n",
    "            'product_id': f'product_{np.random.randint(1, 1000):04d}'\n",
    "        })\n",
    "\n",
    "order_items_df = pd.DataFrame(order_items)\n",
    "\n",
    "print(f\"üìä Created dataset with {len(orders_df):,} orders and {len(order_items_df):,} items\")\n",
    "print(f\"üìÖ Date range: {orders_df['order_purchase_timestamp'].min().date()} to {orders_df['order_purchase_timestamp'].max().date()}\")\n",
    "print(f\"üéØ Delivered orders: {(orders_df['order_status'] == 'delivered').sum():,}\")"
   ]  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è∞ Part 1: Date Arithmetic with Timedelta\n",
    "Learn to calculate delivery times, customer age, and other business metrics using date arithmetic."
   ]  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Basic Date Arithmetic - Calculating Delivery Times"
   ]  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate delivery performance metrics\n",
    "# This replicates our SQL date arithmetic from Thursday\n",
    "\n",
    "delivered_orders = orders_df[orders_df['order_status'] == 'delivered'].copy()\n",
    "\n",
    "# Calculate time differences (equivalent to SQL date subtraction)\n",
    "delivered_orders['total_delivery_time'] = (\n",
    "    delivered_orders['order_delivered_customer_date'] - delivered_orders['order_purchase_timestamp']\n",
    ")\n",
    "delivered_orders['approval_time'] = (\n",
    "    delivered_orders['order_approved_at'] - delivered_orders['order_purchase_timestamp']\n",
    ")\n",
    "delivered_orders['fulfillment_time'] = (\n",
    "    delivered_orders['order_delivered_customer_date'] - delivered_orders['order_approved_at']\n",
    ")\n",
    "\n",
    "# Extract days from timedelta (equivalent to SQL EXTRACT(DAY FROM interval))\n",
    "delivered_orders['delivery_days'] = delivered_orders['total_delivery_time'].dt.days\n",
    "delivered_orders['approval_days'] = delivered_orders['approval_time'].dt.days\n",
    "delivered_orders['fulfillment_days'] = delivered_orders['fulfillment_time'].dt.days\n",
    "\n",
    "# Display sample results\n",
    "sample_metrics = delivered_orders[[\n",
    "    'order_id', 'order_purchase_timestamp', 'order_delivered_customer_date',\n",
    "    'delivery_days', 'approval_days', 'fulfillment_days'\n",
    "]].head(10)\n",
    "\n",
    "print(\"‚è±Ô∏è Delivery Performance Metrics (Python equivalent of SQL date arithmetic):\")\n",
    "print(sample_metrics)"
   ]  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business KPI: Delivery Performance Summary\n",
    "delivery_summary = {\n",
    "    'Total Delivered Orders': len(delivered_orders),\n",
    "    'Average Delivery Days': delivered_orders['delivery_days'].mean().round(2),\n",
    "    'Median Delivery Days': delivered_orders['delivery_days'].median(),\n",
    "    'Average Approval Days': delivered_orders['approval_days'].mean().round(2),\n",
    "    'Orders Delivered ‚â§ 7 Days': (delivered_orders['delivery_days'] <= 7).sum(),\n",
    "    'Fast Delivery Rate (%)': ((delivered_orders['delivery_days'] <= 7).sum() / len(delivered_orders) * 100).round(2)\n",
    "}\n",
    "\n",
    "print(\"üìä DELIVERY PERFORMANCE DASHBOARD\")\n",
    "print(\"=\" * 35)\n",
    "for key, value in delivery_summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "delivered_orders['delivery_days'].hist(bins=30, alpha=0.7, color='skyblue')\n",
    "plt.axvline(delivered_orders['delivery_days'].mean(), color='red', linestyle='--', label=f'Mean: {delivered_orders[\"delivery_days\"].mean():.1f} days')\n",
    "plt.xlabel('Delivery Days')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.title('Distribution of Delivery Times')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "delivery_categories = pd.cut(delivered_orders['delivery_days'], \n",
    "                           bins=[0, 7, 14, 21, float('inf')], \n",
    "                           labels=['‚â§7 days', '8-14 days', '15-21 days', '>21 days'])\n",
    "delivery_categories.value_counts().plot(kind='bar', color=['green', 'orange', 'red', 'darkred'])\n",
    "plt.title('Delivery Performance Categories')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Number of Orders')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Working with Timedelta Objects for Business Rules"
   ]  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create business rules using timedelta operations\n",
    "# Equivalent to SQL INTERVAL operations\n",
    "\n",
    "# Add business deadlines and classifications\n",
    "delivered_orders['expected_delivery'] = delivered_orders['order_purchase_timestamp'] + pd.Timedelta(days=7)\n",
    "delivered_orders['warranty_expiry'] = delivered_orders['order_delivered_customer_date'] + pd.Timedelta(days=90)\n",
    "delivered_orders['order_age'] = datetime.now() - delivered_orders['order_purchase_timestamp']\n",
    "\n",
    "# Business classification based on delivery performance\n",
    "def classify_delivery_performance(delivery_days):\n",
    "    if delivery_days <= 7:\n",
    "        return 'Fast Delivery'\n",
    "    elif delivery_days <= 14:\n",
    "        return 'Standard Delivery'\n",
    "    else:\n",
    "        return 'Slow Delivery'\n",
    "\n",
    "delivered_orders['delivery_classification'] = delivered_orders['delivery_days'].apply(\n",
    "    classify_delivery_performance\n",
    ")\n",
    "\n",
    "# Late delivery analysis\n",
    "delivered_orders['is_late'] = (\n",
    "    delivered_orders['order_delivered_customer_date'] > delivered_orders['order_estimated_delivery_date']\n",
    ")\n",
    "delivered_orders['delay_days'] = (\n",
    "    delivered_orders['order_delivered_customer_date'] - delivered_orders['order_estimated_delivery_date']\n",
    ").dt.days\n",
    "delivered_orders['delay_days'] = delivered_orders['delay_days'].clip(lower=0)  # Only positive delays\n",
    "\n",
    "# Business insights\n",
    "performance_summary = delivered_orders['delivery_classification'].value_counts()\n",
    "late_delivery_rate = delivered_orders['is_late'].mean() * 100\n",
    "avg_delay = delivered_orders[delivered_orders['is_late']]['delay_days'].mean()\n",
    "\n",
    "print(\"üöö DELIVERY PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 35)\n",
    "print(performance_summary)\n",
    "print(f\"\\nüìà Late Delivery Rate: {late_delivery_rate:.1f}%\")\n",
    "print(f\"üìä Average Delay (when late): {avg_delay:.1f} days\")\n",
    "\n",
    "# Sample of classified orders\n",
    "sample_classified = delivered_orders[[\n",
    "    'order_id', 'delivery_days', 'delivery_classification', 'is_late', 'delay_days'\n",
    "]].head(10)\n",
    "\n",
    "print(\"\\nüìã Sample Delivery Classifications:\")\n",
    "print(sample_classified)"
   ]  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Part 2: Advanced Time Series Analysis\n",
    "Implement sophisticated temporal analysis techniques for business intelligence."
   ]  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Period-over-Period Comparisons using shift()"
   ]  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create monthly revenue analysis with growth calculations\n",
    "# Python equivalent of SQL LAG window functions\n",
    "\n",
    "# First, merge orders with order items to get revenue data\n",
    "order_revenue = orders_df.merge(order_items_df, on='order_id', how='inner')\n",
    "\n",
    "# Monthly revenue analysis\n",
    "monthly_revenue = order_revenue.groupby(\n",
    "    order_revenue['order_purchase_timestamp'].dt.to_period('M')\n",
    ").agg({\n",
    "    'order_id': 'nunique',\n",
    "    'price': 'sum',\n",
    "    'customer_id': 'nunique'\n",
    "}).rename(columns={\n",
    "    'order_id': 'total_orders',\n",
    "    'price': 'total_revenue',\n",
    "    'customer_id': 'unique_customers'\n",
    "})\n",
    "\n",
    "# Calculate period-over-period changes (equivalent to SQL LAG)\n",
    "monthly_revenue['prev_month_orders'] = monthly_revenue['total_orders'].shift(1)\n",
    "monthly_revenue['prev_month_revenue'] = monthly_revenue['total_revenue'].shift(1)\n",
    "\n",
    "# Calculate growth rates\n",
    "monthly_revenue['orders_mom_growth'] = (\n",
    "    (monthly_revenue['total_orders'] - monthly_revenue['prev_month_orders']) / \n",
    "    monthly_revenue['prev_month_orders'] * 100\n",
    ").round(2)\n",
    "\n",
    "monthly_revenue['revenue_mom_growth'] = (\n",
    "    (monthly_revenue['total_revenue'] - monthly_revenue['prev_month_revenue']) / \n",
    "    monthly_revenue['prev_month_revenue'] * 100\n",
    ").round(2)\n",
    "\n",
    "# Using pandas pct_change() for easier growth calculation\n",
    "monthly_revenue['orders_growth_pct'] = (monthly_revenue['total_orders'].pct_change() * 100).round(2)\n",
    "monthly_revenue['revenue_growth_pct'] = (monthly_revenue['total_revenue'].pct_change() * 100).round(2)\n",
    "\n",
    "print(\"üìä Month-over-Month Growth Analysis (Python equivalent of SQL LAG functions):\")\n",
    "print(monthly_revenue[['total_orders', 'total_revenue', 'orders_growth_pct', 'revenue_growth_pct']].head(12))"
   ]  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Rolling Windows and Moving Averages"
   ]  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create daily order trends with rolling averages\n",
    "# Python equivalent of SQL window functions\n",
    "\n",
    "# Daily order counts\n",
    "daily_orders = orders_df.groupby(\n",
    "    orders_df['order_purchase_timestamp'].dt.date\n",
    ")['order_id'].count().reset_index()\n",
    "\n",
    "daily_orders.columns = ['order_date', 'daily_orders']\n",
    "daily_orders['order_date'] = pd.to_datetime(daily_orders['order_date'])\n",
    "daily_orders = daily_orders.sort_values('order_date').reset_index(drop=True)\n",
    "\n",
    "# Calculate rolling averages (equivalent to SQL ROWS BETWEEN)\n",
    "daily_orders['rolling_7d_avg'] = daily_orders['daily_orders'].rolling(window=7, min_periods=1).mean().round(2)\n",
    "daily_orders['rolling_30d_avg'] = daily_orders['daily_orders'].rolling(window=30, min_periods=1).mean().round(2)\n",
    "\n",
    "# Calculate rolling statistics\n",
    "daily_orders['rolling_7d_std'] = daily_orders['daily_orders'].rolling(window=7, min_periods=1).std().round(2)\n",
    "daily_orders['rolling_7d_max'] = daily_orders['daily_orders'].rolling(window=7, min_periods=1).max()\n",
    "daily_orders['rolling_7d_min'] = daily_orders['daily_orders'].rolling(window=7, min_periods=1).min()\n",
    "\n",
    "# Day-over-day changes\n",
    "daily_orders['daily_change'] = daily_orders['daily_orders'].diff()\n",
    "daily_orders['daily_change_pct'] = daily_orders['daily_orders'].pct_change() * 100\n",
    "\n",
    "print(\"üìä Daily Order Trends with Rolling Statistics:\")\n",
    "print(daily_orders[['order_date', 'daily_orders', 'rolling_7d_avg', 'rolling_30d_avg', 'daily_change']].head(15))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(daily_orders['order_date'], daily_orders['daily_orders'], alpha=0.3, label='Daily Orders', color='lightblue')\n",
    "plt.plot(daily_orders['order_date'], daily_orders['rolling_7d_avg'], label='7-Day Average', color='blue')\n",
    "plt.plot(daily_orders['order_date'], daily_orders['rolling_30d_avg'], label='30-Day Average', color='red')\n",
    "plt.title('Daily Orders with Moving Averages')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(daily_orders['order_date'], daily_orders['daily_change'], color='green', alpha=0.7)\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "plt.title('Day-over-Day Change in Orders')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Change in Orders')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Business insights\n",
    "avg_daily_orders = daily_orders['daily_orders'].mean()\n",
    "volatility = daily_orders['daily_orders'].std()\n",
    "trend_direction = 'Increasing' if daily_orders['rolling_30d_avg'].iloc[-1] > daily_orders['rolling_30d_avg'].iloc[-30] else 'Decreasing'\n",
    "\n",
    "print(f\"\\nüìà BUSINESS INSIGHTS:\")\n",
    "print(f\"Average Daily Orders: {avg_daily_orders:.1f}\")\n",
    "print(f\"Daily Volatility (Std Dev): {volatility:.1f}\")\n",
    "print(f\"30-Day Trend: {trend_direction}\")"
   ]  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Seasonal Analysis and Patterns"
   ]  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive seasonal analysis\n",
    "# Python equivalent of our SQL seasonal pattern detection\n",
    "\n",
    "# Add temporal features for seasonal analysis\n",
    "order_revenue['month'] = order_revenue['order_purchase_timestamp'].dt.month\n",
    "order_revenue['quarter'] = order_revenue['order_purchase_timestamp'].dt.quarter\n",
    "order_revenue['year'] = order_revenue['order_purchase_timestamp'].dt.year\n",
    "order_revenue['month_name'] = order_revenue['order_purchase_timestamp'].dt.month_name()\n",
    "order_revenue['day_of_week'] = order_revenue['order_purchase_timestamp'].dt.dayofweek\n",
    "order_revenue['day_name'] = order_revenue['order_purchase_timestamp'].dt.day_name()\n",
    "\n",
    "# Monthly seasonal analysis\n",
    "monthly_seasonal = order_revenue.groupby('month').agg({\n",
    "    'order_id': 'nunique',\n",
    "    'price': 'sum',\n",
    "    'customer_id': 'nunique'\n",
    "}).rename(columns={\n",
    "    'order_id': 'total_orders',\n",
    "    'price': 'total_revenue',\n",
    "    'customer_id': 'unique_customers'\n",
    "})\n",
    "\n",
    "# Calculate seasonal indices (comparing each month to yearly average)\n",
    "yearly_avg_orders = monthly_seasonal['total_orders'].mean()\n",
    "yearly_avg_revenue = monthly_seasonal['total_revenue'].mean()\n",
    "\n",
    "monthly_seasonal['seasonal_index_orders'] = (monthly_seasonal['total_orders'] / yearly_avg_orders * 100).round(2)\n",
    "monthly_seasonal['seasonal_index_revenue'] = (monthly_seasonal['total_revenue'] / yearly_avg_revenue * 100).round(2)\n",
    "\n",
    "# Add month names\n",
    "monthly_seasonal['month_name'] = pd.to_datetime(monthly_seasonal.index, format='%m').month_name()\n",
    "\n",
    "print(\"üåø SEASONAL PATTERN ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "print(monthly_seasonal[['month_name', 'total_orders', 'total_revenue', 'seasonal_index_orders', 'seasonal_index_revenue']])\n",
    "\n",
    "# Identify peak and low seasons\n",
    "peak_month_orders = monthly_seasonal['seasonal_index_orders'].idxmax()\n",
    "low_month_orders = monthly_seasonal['seasonal_index_orders'].idxmin()\n",
    "peak_month_revenue = monthly_seasonal['seasonal_index_revenue'].idxmax()\n",
    "\n",
    "print(f\"\\nüìä SEASONAL INSIGHTS:\")\n",
    "print(f\"Peak Order Month: {monthly_seasonal.loc[peak_month_orders, 'month_name']} (Index: {monthly_seasonal.loc[peak_month_orders, 'seasonal_index_orders']})\")\n",
    "print(f\"Low Order Month: {monthly_seasonal.loc[low_month_orders, 'month_name']} (Index: {monthly_seasonal.loc[low_month_orders, 'seasonal_index_orders']})\")\n",
    "print(f\"Peak Revenue Month: {monthly_seasonal.loc[peak_month_revenue, 'month_name']} (Index: {monthly_seasonal.loc[peak_month_revenue, 'seasonal_index_revenue']})\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Monthly orders\n",
    "axes[0, 0].bar(monthly_seasonal['month_name'], monthly_seasonal['total_orders'], color='skyblue')\n",
    "axes[0, 0].set_title('Orders by Month')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Monthly revenue\n",
    "axes[0, 1].bar(monthly_seasonal['month_name'], monthly_seasonal['total_revenue'], color='lightgreen')\n",
    "axes[0, 1].set_title('Revenue by Month')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Seasonal indices\n",
    "axes[1, 0].plot(monthly_seasonal.index, monthly_seasonal['seasonal_index_orders'], marker='o', color='blue')\n",
    "axes[1, 0].axhline(y=100, color='red', linestyle='--', alpha=0.7, label='Average (100)')\n",
    "axes[1, 0].set_title('Seasonal Index - Orders')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Day of week analysis\n",
    "dow_analysis = order_revenue.groupby('day_name')['order_id'].nunique().reindex(\n",
    "    ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    ")\n",
    "axes[1, 1].bar(dow_analysis.index, dow_analysis.values, color='orange')\n",
    "axes[1, 1].set_title('Orders by Day of Week')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë• Part 3: Customer Cohort Analysis\n",
    "Advanced time-based customer analytics for understanding retention and lifetime value."
   ]  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer cohort analysis based on first purchase month\n",
    "# Python equivalent of our SQL cohort analysis\n",
    "\n",
    "# Identify first purchase date for each customer\n",
    "customer_first_purchase = orders_df.groupby('customer_id')['order_purchase_timestamp'].min().reset_index()\n",
    "customer_first_purchase.columns = ['customer_id', 'first_purchase_date']\n",
    "customer_first_purchase['cohort_month'] = customer_first_purchase['first_purchase_date'].dt.to_period('M')\n",
    "\n",
    "# Merge back with all orders to track customer activity\n",
    "orders_with_cohort = orders_df.merge(customer_first_purchase, on='customer_id')\n",
    "orders_with_cohort['order_period'] = orders_with_cohort['order_purchase_timestamp'].dt.to_period('M')\n",
    "\n",
    "# Calculate months since first purchase\n",
    "orders_with_cohort['months_since_first_purchase'] = (\n",
    "    orders_with_cohort['order_period'] - orders_with_cohort['cohort_month']\n",
    ").apply(lambda x: x.n)\n",
    "\n",
    "# Create cohort table\n",
    "cohort_data = orders_with_cohort.groupby(['cohort_month', 'months_since_first_purchase'])['customer_id'].nunique().reset_index()\n",
    "cohort_data.columns = ['cohort_month', 'period_number', 'active_customers']\n",
    "\n",
    "# Calculate cohort sizes (customers in each cohort)\n",
    "cohort_sizes = customer_first_purchase.groupby('cohort_month')['customer_id'].nunique()\n",
    "\n",
    "# Merge cohort sizes\n",
    "cohort_data = cohort_data.merge(\n",
    "    cohort_sizes.reset_index().rename(columns={'customer_id': 'cohort_size'}),\n",
    "    on='cohort_month'\n",
    ")\n",
    "\n",
    "# Calculate retention rates\n",
    "cohort_data['retention_rate'] = (cohort_data['active_customers'] / cohort_data['cohort_size'] * 100).round(2)\n",
    "\n",
    "# Focus on first 12 months and recent cohorts\n",
    "cohort_analysis = cohort_data[\n",
    "    (cohort_data['period_number'] <= 12) & \n",
    "    (cohort_data['cohort_month'] >= '2017-01')\n",
    "]\n",
    "\n",
    "print(\"üë• CUSTOMER COHORT ANALYSIS\")\n",
    "print(\"=\" * 35)\n",
    "print(\"Sample cohort retention data:\")\n",
    "print(cohort_analysis[cohort_analysis['cohort_month'] == '2017-01'].head(12))\n",
    "\n",
    "# Create cohort retention matrix\n",
    "cohort_matrix = cohort_analysis.pivot(index='cohort_month', columns='period_number', values='retention_rate')\n",
    "\n",
    "print(\"\\nüìä Cohort Retention Matrix (First 6 months):\")\n",
    "print(cohort_matrix.iloc[:6, :7])  # Show first 6 cohorts, first 7 periods\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(cohort_matrix.iloc[:8, :13], annot=True, fmt='.1f', cmap='Blues', \n",
    "           cbar_kws={'label': 'Retention Rate (%)'}, vmin=0, vmax=100)\n",
    "plt.title('Customer Cohort Retention Heatmap')\n",
    "plt.xlabel('Period Number (Months Since First Purchase)')\n",
    "plt.ylabel('Cohort Month')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Key insights\n",
    "avg_month_1_retention = cohort_matrix[1].mean()\n",
    "avg_month_6_retention = cohort_matrix[6].mean()\n",
    "avg_month_12_retention = cohort_matrix[12].mean()\n",
    "\n",
    "print(f\"\\nüìà COHORT INSIGHTS:\")\n",
    "print(f\"Average Month 1 Retention: {avg_month_1_retention:.1f}%\")\n",
    "print(f\"Average Month 6 Retention: {avg_month_6_retention:.1f}%\")\n",
    "print(f\"Average Month 12 Retention: {avg_month_12_retention:.1f}%\")"
   ]  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåç Nigerian Business Context Analysis\n",
    "Applying our temporal analysis to Nigerian market conditions."
   ]  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nigerian-specific temporal analysis\n",
    "# Adapting Brazilian data patterns to Nigerian business context\n",
    "\n",
    "# Define Nigerian seasons and holidays\n",
    "def get_nigerian_season(month):\n",
    "    if month in [5, 6, 7, 8, 9, 10]:\n",
    "        return 'Rainy Season'\n",
    "    else:\n",
    "        return 'Dry Season'\n",
    "\n",
    "def get_nigerian_business_period(month):\n",
    "    if month == 12:\n",
    "        return 'Christmas Season'\n",
    "    elif month == 10:\n",
    "        return 'Independence Month'\n",
    "    elif month == 9:\n",
    "        return 'Back-to-School'\n",
    "    elif month in [4, 5]:\n",
    "        return 'Easter/Salary Season'\n",
    "    else:\n",
    "        return 'Regular Period'\n",
    "\n",
    "# Apply Nigerian context to our data\n",
    "nigeria_analysis = order_revenue.copy()\n",
    "nigeria_analysis['nigerian_season'] = nigeria_analysis['month'].apply(get_nigerian_season)\n",
    "nigeria_analysis['business_period'] = nigeria_analysis['month'].apply(get_nigerian_business_period)\n",
    "\n",
    "# Seasonal impact on delivery performance\n",
    "seasonal_delivery = delivered_orders.copy()\n",
    "seasonal_delivery['nigerian_season'] = seasonal_delivery['order_purchase_timestamp'].dt.month.apply(get_nigerian_season)\n",
    "\n",
    "seasonal_performance = seasonal_delivery.groupby('nigerian_season').agg({\n",
    "    'delivery_days': ['mean', 'median', 'count'],\n",
    "    'is_late': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "seasonal_performance.columns = ['avg_delivery_days', 'median_delivery_days', 'total_orders', 'late_delivery_rate']\n",
    "seasonal_performance['late_delivery_rate'] = seasonal_performance['late_delivery_rate'] * 100\n",
    "\n",
    "print(\"üåç NIGERIAN SEASONAL DELIVERY ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "print(seasonal_performance)\n",
    "\n",
    "# Business period revenue analysis\n",
    "business_period_analysis = nigeria_analysis.groupby('business_period').agg({\n",
    "    'order_id': 'nunique',\n",
    "    'price': 'sum'\n",
    "}).rename(columns={\n",
    "    'order_id': 'total_orders',\n",
    "    'price': 'total_revenue'\n",
    "})\n",
    "\n",
    "# Calculate seasonal multipliers for business planning\n",
    "avg_period_orders = business_period_analysis['total_orders'].mean()\n",
    "business_period_analysis['demand_multiplier'] = (\n",
    "    business_period_analysis['total_orders'] / avg_period_orders\n",
    ").round(2)\n",
    "\n",
    "# Add business recommendations\n",
    "def get_business_recommendation(multiplier):\n",
    "    if multiplier >= 1.2:\n",
    "        return 'Increase inventory 20%+'\n",
    "    elif multiplier >= 1.1:\n",
    "        return 'Increase inventory 10%+'\n",
    "    elif multiplier <= 0.8:\n",
    "        return 'Reduce inventory 20%'\n",
    "    else:\n",
    "        return 'Maintain normal levels'\n",
    "\n",
    "business_period_analysis['recommendation'] = business_period_analysis['demand_multiplier'].apply(\n",
    "    get_business_recommendation\n",
    ")\n",
    "\n",
    "print(\"\\nüéØ NIGERIAN BUSINESS PERIOD ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "print(business_period_analysis)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Seasonal delivery performance\n",
    "seasonal_performance['avg_delivery_days'].plot(kind='bar', ax=axes[0, 0], color=['skyblue', 'orange'])\n",
    "axes[0, 0].set_title('Average Delivery Days by Nigerian Season')\n",
    "axes[0, 0].set_ylabel('Days')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Business period demand\n",
    "business_period_analysis['demand_multiplier'].plot(kind='bar', ax=axes[0, 1], color='lightgreen')\n",
    "axes[0, 1].axhline(y=1, color='red', linestyle='--', alpha=0.7, label='Average Demand')\n",
    "axes[0, 1].set_title('Demand Multiplier by Business Period')\n",
    "axes[0, 1].set_ylabel('Multiplier')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Monthly pattern with Nigerian context\n",
    "monthly_nigeria = nigeria_analysis.groupby('month')['order_id'].nunique()\n",
    "colors = ['red' if month in [12, 10, 9] else 'skyblue' for month in monthly_nigeria.index]\n",
    "monthly_nigeria.plot(kind='bar', ax=axes[1, 0], color=colors)\n",
    "axes[1, 0].set_title('Monthly Orders (Red = Nigerian Holiday Months)')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Orders')\n",
    "\n",
    "# Seasonal order distribution\n",
    "seasonal_orders = nigeria_analysis.groupby('nigerian_season')['order_id'].nunique()\n",
    "seasonal_orders.plot(kind='pie', ax=axes[1, 1], autopct='%1.1f%%')\n",
    "axes[1, 1].set_title('Order Distribution by Nigerian Season')\n",
    "axes[1, 1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ KEY NIGERIAN BUSINESS INSIGHTS:\")\n",
    "print(f\"‚Ä¢ Rainy season shows {'higher' if seasonal_performance.loc['Rainy Season', 'avg_delivery_days'] > seasonal_performance.loc['Dry Season', 'avg_delivery_days'] else 'lower'} delivery times\")\n",
    "print(f\"‚Ä¢ Christmas season shows {business_period_analysis.loc['Christmas Season', 'demand_multiplier']:.1f}x normal demand\")\n",
    "print(f\"‚Ä¢ Independence month shows {business_period_analysis.loc['Independence Month', 'demand_multiplier']:.1f}x normal demand\")\n",
    "print(f\"‚Ä¢ Recommendation for Christmas: {business_period_analysis.loc['Christmas Season', 'recommendation']}\")"
   ]  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ SQL vs Python DateTime Comparison\n",
    "Summary of equivalent operations and when to use each tool."
   ]  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table of SQL vs Python datetime operations\n",
    "comparison_data = {\n",
    "    'Operation': [\n",
    "        'Extract Month',\n",
    "        'Extract Year',\n",
    "        'Date Truncation',\n",
    "        'Date Arithmetic',\n",
    "        'Period Comparison',\n",
    "        'Rolling Average',\n",
    "        'Date Formatting',\n",
    "        'Null Handling',\n",
    "        'Timezone Conversion',\n",
    "        'Seasonal Analysis'\n",
    "    ],\n",
    "    'SQL Approach': [\n",
    "        'EXTRACT(MONTH FROM date)',\n",
    "        'EXTRACT(YEAR FROM date)',\n",
    "        'DATE_TRUNC(\"month\", date)',\n",
    "        'date1 - date2',\n",
    "        'LAG(value) OVER (ORDER BY date)',\n",
    "        'AVG(value) OVER (ROWS 6 PRECEDING)',\n",
    "        'TO_CHAR(date, \"YYYY-MM-DD\")',\n",
    "        'WHERE date IS NOT NULL',\n",
    "        'AT TIME ZONE \"UTC\"',\n",
    "        'CASE WHEN EXTRACT(MONTH...) THEN...'\n",
    "    ],\n",
    "    'Python Pandas Approach': [\n",
    "        'df[\"date\"].dt.month',\n",
    "        'df[\"date\"].dt.year',\n",
    "        'df.resample(\"M\")',\n",
    "        'df[\"date1\"] - df[\"date2\"]',\n",
    "        'df[\"value\"].shift(1)',\n",
    "        'df[\"value\"].rolling(7).mean()',\n",
    "        'df[\"date\"].dt.strftime(\"%Y-%m-%d\")',\n",
    "        'df[\"date\"].notna()',\n",
    "        'df[\"date\"].dt.tz_convert(\"UTC\")',\n",
    "        'df[\"month\"].apply(seasonal_function)'\n",
    "    ],\n",
    "    'Best Use Case': [\n",
    "        'Both equally effective',\n",
    "        'Both equally effective',\n",
    "        'Python better for analysis',\n",
    "        'Both handle well',\n",
    "        'Python more intuitive',\n",
    "        'Python much better',\n",
    "        'Python more flexible',\n",
    "        'Both handle well',\n",
    "        'Python more comprehensive',\n",
    "        'Python better for complex logic'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"üîÑ SQL vs PYTHON DATETIME OPERATIONS COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nüéØ WHEN TO USE EACH TOOL:\")\n",
    "print(\"\\nSQL DateTime Operations:\")\n",
    "print(\"‚úÖ Database-level filtering and aggregation\")\n",
    "print(\"‚úÖ Large dataset initial processing\")\n",
    "print(\"‚úÖ Simple date extractions and basic arithmetic\")\n",
    "print(\"‚úÖ Integration with existing database workflows\")\n",
    "\n",
    "print(\"\\nPython DateTime Operations:\")\n",
    "print(\"‚úÖ Complex time series analysis\")\n",
    "print(\"‚úÖ Advanced statistical operations\")\n",
    "print(\"‚úÖ Data visualization and dashboards\")\n",
    "print(\"‚úÖ Machine learning and forecasting\")\n",
    "print(\"‚úÖ Flexible data manipulation and transformation\")\n",
    "\n",
    "print(\"\\nüí° BEST PRACTICE:\")\n",
    "print(\"Use SQL for initial data extraction and basic filtering,\")\n",
    "print(\"then use Python for advanced analysis and visualization!\")"
   ]  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Summary and Next Steps\n",
    "\n",
    "### üéØ Key Achievements\n",
    "You've now mastered Python datetime operations equivalent to Thursday's SQL analysis:\n",
    "\n",
    "1. **Date Component Extraction**: Using `.dt` accessor for business reporting\n",
    "2. **Date Arithmetic**: Calculating delivery times and business metrics\n",
    "3. **Time Series Analysis**: Rolling windows, period comparisons, and trend analysis\n",
    "4. **Seasonal Analysis**: Identifying business patterns and seasonal trends\n",
    "5. **Cohort Analysis**: Understanding customer retention and lifetime value\n",
    "6. **Nigerian Context**: Adapting analysis for local business conditions\n",
    "\n",
    "### üîÑ SQL + Python Integration\n",
    "The real power comes from combining both tools:\n",
    "- **Extract** data efficiently with SQL\n",
    "- **Analyze** deeply with Python\n",
    "- **Visualize** insights with Python libraries\n",
    "- **Store** results back to database with SQL\n",
    "\n",
    "### üöÄ Upcoming Applications\n",
    "These datetime skills will be essential for:\n",
    "- **Google Looker Studio**: Creating time-based dashboards\n",
    "- **Streamlit**: Building interactive temporal analytics apps\n",
    "- **Advanced Analytics**: Time series forecasting and trend prediction\n",
    "- **Business Intelligence**: Automated reporting and KPI tracking\n",
    "\n",
    "### üìä Your Next Challenge\n",
    "In the exercises, you'll apply these concepts to real business scenarios, comparing your Python results with Thursday's SQL findings!"
   ]  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}